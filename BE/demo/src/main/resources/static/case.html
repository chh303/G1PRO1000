<!DOCTYPE html>
<html lang="no">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <meta name="description" content="Case study om gr√∏nn kode og b√¶rekraftige programmeringspraksiser." />
  <title>Case</title>

  <link rel="stylesheet" href="css/case.css" />
  <link rel="stylesheet" href="css/header.css" />
  <link rel="stylesheet" href="css/footer.css" />
  <link rel="stylesheet" href="css/chatbot.css" />
  <link rel="icon" href="/images/favicon.ico" type="image/x-icon" />

  <script src="/script/header.js" defer></script>
  <script src="/script/footer.js" defer></script>
  <script src="/script/chatbot.js" defer></script>
</head>

<body data-page="case.html">

  <h1>Case Study</h1>

  <main class="pdf-container">
    <div class="pdf-grid">
      <!-- Boks 1 -->
      <section class="pdf-info-boks">
        <h2 class="pdf-tittel">Gr√∏nn Koding</h2>
        <p class="pdf-beskrivelse">
          Studien Green Prompting fra Lancaster University unders√∏ker hvordan ulike egenskaper ved prompt og respons p√•virker energiforbruket ved bruk av store spr√•kmodeller (LLMs) under inferens. Forfatterne gjennomf√∏rte eksperimenter med tre √•pne LLM-er ‚Äì Mistral 7B, Gemma 7B og Vicuna 7B ‚Äì p√• tre ulike oppgaver: sp√∏rsm√•lsbesvarelse, sentimentanalyse og tekstgenerering. Gjennom hele 891‚ÄØ000 eksperimentelle kj√∏ringer ble energibruk, latenstid og responslengde m√•lt og analysert. Studien viser at den semantiske betydningen av prompten ‚Äì alts√• hva prompten ber modellen om √• gj√∏re ‚Äì har st√∏rre innvirkning p√• energiforbruk enn promptens lengde. Lengre og mer komplekse svar (ofte utl√∏st av √•pne oppgaver som ‚Äúforklar‚Äù, ‚Äúanalyser‚Äù osv.) √∏ker energiforbruket betydelig, og dette ble funnet √• v√¶re sterkere korrelert med energikostnad enn antall ord i prompten.
          <br><br>
          Resultatene fremhever ogs√• at selv mellom modeller med lik arkitektur, varierer energiforbruket betydelig, b√•de p√• grunn av forskjeller i responslengde og ‚Äúper-token‚Äù-kostnad. Gemma genererte de lengste svarene, og dermed det h√∏yeste totale energiforbruket, selv om den brukte minst energi per token. Studien viser ogs√• at enkelte n√∏kkelord i promptene, som ‚Äúforklar‚Äù eller ‚Äúanalyser‚Äù, ofte f√∏rer til mer energikrevende svar ‚Äì et viktig funn for fremtidig arbeid med ‚Äúgr√∏nn‚Äù promptutforming. Et interessant tillegg var hvordan Vicuna ofte bruker emotikoner, noe som i noen tilfeller √∏kte energiforbruket. Studien konkluderer med at smart promptdesign ‚Äì spesielt med tanke p√• semantikk og oppgavetype ‚Äì kan bli et viktig verkt√∏y i arbeidet med mer b√¶rekraftig AI-bruk.
        </p>
        <div class="image-crop">
          <img src="/images/stock1.jpg">
        </div>
        <button class="pdf-knapp" onclick="visPdf('https://arxiv.org/pdf/2503.10666')">Les PDF</button>
      </section>

      <!-- Boks 2 -->
      <section class="pdf-info-boks">
        <h2 class="pdf-tittel">Energieffektive Algoritmer</h2>
        <p class="pdf-beskrivelse">
          Studien ‚ÄúLearn to Code Sustainably: An Empirical Study on LLM-based Green Code Generation‚Äù unders√∏ker hvorvidt generative AI-verkt√∏y som GitHub Copilot, OpenAI ChatGPT og Amazon CodeWhisperer er i stand til √• generere b√¶rekraftig kode ‚Äì alts√• kode som er b√•de funksjonell og energieffektiv. Forfatterne introduserer et nytt begrep kalt Green Capacity (GC), som m√•ler hvor milj√∏vennlig en kode er basert p√• fire faktorer: kj√∏retid, minnebruk, energiforbruk og antall FLOPs (floating-point operations). Studien sammenligner kode generert av AI-modellene med kode skrevet av topp 0.05%-bidragsytere p√• LeetCode, og bruker et utvalg problemer fra plattformen for √• teste modellene.
          <br><br>
          Resultatene viser at selv om AI-modellene kan produsere korrekt og delvis optimalisert kode, er de generelt mindre effektive enn den beste menneskeskrevne koden. Spesielt ChatGPT og Copilot viste h√∏yere Green Capacity i flere tilfeller, men de mangler fortsatt konsistent forst√•else for b√¶rekraftsm√•l som energiforbruk og minneoptimalisering. Studien konkluderer med at det er behov for videreutvikling og trening av slike verkt√∏y med eksplisitte b√¶rekraftsm√•l for √• virkelig kunne redusere karbonavtrykket i programvareutvikling. Dette blir stadig viktigere i takt med √∏kt ettersp√∏rsel etter data og beregningstunge l√∏sninger i moderne IT.
        </p>
        <div class="image-crop">
          <img src="/images/stock2.jpg" style="width: 460px; height: auto;">
        </div>
        <button class="pdf-knapp" onclick="visPdf('https://arxiv.org/pdf/2403.03344')">Les PDF</button>
      </section>

      <!-- Boks 3 -->
      <section class="pdf-info-boks">
        <h2 class="pdf-tittel">Less is More:<br> Towards Green Code Large Language Models via
          Unified Structural Pruning</h2>
        <p class="pdf-beskrivelse">
          I denne studien introduseres Flab-Pruner, en strukturert pruning-metode som reduserer st√∏rrelsen p√• store spr√•kmodeller (LLMs) brukt til generativ kode, uten √• g√• p√• bekostning av ytelse. Flab-Pruner kombinerer tre niv√•er av pruning: vokabular, lag og feed-forward-nettverk (FFN), og benytter KL-divergens som m√•lfunksjon for √• bevare modellens genereringsevne. For √• forbedre ytelsen etter pruning, introduseres en spesialtilpasset code instruction tuning-strategi.
          <br><br>
          Metoden evalueres p√• modeller som CodeQwen, NxCode og CodeSlerp, og oppn√•r opptil 97‚ÄØ% av original ytelse etter √• ha fjernet 22‚ÄØ% av parametrene. Samtidig gir den betydelige gevinster i lagring, GPU-bruk, beregningskostnad og CO‚ÇÇ-utslipp. Studien viser ogs√• at modellen bevarer robusthet under ulike typer perturbasjoner, og at post-trening (f.eks. med LoRA) ytterligere forbedrer b√•de ytelse og robusthet.
          <br><br>
          Dette arbeidet bidrar til gr√∏nnere programvareutvikling og gir en effektiv vei videre for bruk av LLM-er i kodeintelligensoppgaver med lavere milj√∏avtrykk.
        </p>
        <div class="image-crop">
          <img src="/images/stock3.jpg" style="width: 460px; height: auto;">
        </div>
        <button class="pdf-knapp" onclick="visPdf('https://arxiv.org/pdf/2412.15921')">Les PDF</button>
      </section>
    </div>
  </main>

  <!-- üì¶ Fullskjerms PDF-overlay -->
  <div id="pdf-overlay" class="pdf-overlay">
    <div class="pdf-overlay-content">
      <button class="close-btn" onclick="lukkPdf()">Lukk</button>
      <iframe id="pdf-frame" src="" title="Fullskjerm PDF"></iframe>
    </div>
  </div>

  <div id="chatbot-placeholder"></div>

  <!-- üìú JavaScript for fullskjerms PDF -->
  <script>
    function visPdf(url) {
      const overlay = document.getElementById("pdf-overlay");
      const iframe = document.getElementById("pdf-frame");
      iframe.src = url;
      overlay.style.display = "flex";
    }

    function lukkPdf() {
      const overlay = document.getElementById("pdf-overlay");
      const iframe = document.getElementById("pdf-frame");
      iframe.src = "";
      overlay.style.display = "none";
    }
    // Lukk ved klikk utenfor PDF-vinduet
    document.getElementById("pdf-overlay").addEventListener("click", function (event) {
      const content = document.querySelector(".pdf-overlay-content");
      if (!content.contains(event.target)) {
        lukkPdf();
      }
    });
  </script>
</body>
</html>
